function [coi nsamples eyeStds] = coiForVideo(whichVideoNumber, minDistance, coiType, shotBoundaries)
% For a particular video number, compute a COI for each frame using
% one of several possible strategies for a "democratic center of interest".
%
% INPUT
%  whichVideoNumber     Video id from 1-200 from which to extract the data.
%  minDistance          If we are doing multiple COIs, the minimum distance
%                       in pixels that the centers of the two clusters can
%                       be apart (before they are really only one cluster)
%  coiType              The algorithm used to compute the COI. See the
%                       switch statement below for the details of this.
%  shotBoundaries       A list of all the instances of the shot changing
%                       for this particular video, which is used in some of
%                       the shot-based algorithms. In ms from start of the
%                       video file.
% OUTPUT
%  coi          An array of either 1 or 2 structs, of the form
%               x,y,t,missing, that consist of a decision about the COI for
%               each frame of the video. The first will be the primary COI,
%               the second entry the secondary (if we meet the criteria for
%               having a secondary)
%  nsamples     How many eyetrace samples went into computing the coi at
%               each video frame? Array of integers. 2D array if numCOIs >
%               1 (with first dimension being which COI).
%  eyeStds      The standard deviation of the gaze points used to compute
%               the COI at each point. 2D array if numCOIs >
%               1 (with first dimension being which COI).
%
% Usage: [coi nsamples eyeStds] = coiForVideo(whichVideoNumber, minDistance, coiType, shotBoundaries)

if ~exist('minDistance')
    minDistance = 0;
end
if ~exist('coiType')
    coiType = 1;
end

eyetrackDir = '/Users/danielsaunders/Free norm - eyetrack data';

% This file maps eyetrack data files to video numbers, and is generated by
% gatherVideoNumbers.m
load 'video number lookup.mat'

% Load in all the eyetracking data for this video
subjsForVid = find(videoNumbers == whichVideoNumber);
for i = 1:length(subjsForVid)
    load([eyetrackDir filesep eyetrackFiles{subjsForVid(i)}]);
    temp.x = eyetrackRecord.x;
    temp.y = eyetrackRecord.y;
    temp.t = eyetrackRecord.t;
    temp.missing = eyetrackRecord.missing;
    
    eyeTraces(i) = temp;
end

switch coiType
    case 1  % Regular COI, computing median at each time point and then smoothing. Compute a secondary COI as well.
        [coi nsamples eyeStds] = coiFromEyeTraces(eyeTraces, 2, minDistance);
    case 2 % A single position for the entire video
        [coi nsamples eyeStds] = coiOverallMedian(eyeTraces);
    case 3 % Static COI for each shot, taking the median over all
        coi = coiByShot(eyeTraces, 2, minDistance, shotBoundaries, true);
    case 4 % Static COI for each shot, taking the median of all the cois at particular positions. Doesn't seem to work at the moment.
        coi = coiByShot(eyeTraces, 2, minDistance, shotBoundaries, false);
    case 5  % Regular COI, computing median at each time point and then smoothing, except with only 1 coi.
        [coi nsamples eyeStds] = coiFromEyeTraces(eyeTraces, 1, minDistance);
        % Make a dummy secondary COI (should only use this if doing the COI
        % dot, which assumes a secondary COI)
%         coi(2).t = coi(1).t;
%         coi(2).missing = ones(length(coi(1).t),1);
    case 6 % First eyetrace only
        coi = eyeTraces(1);
end
